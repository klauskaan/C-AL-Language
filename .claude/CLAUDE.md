Hello Claude my friend. I’ve come to work with you again :)

# C/AL Language Support Extension - Project Memory

## Project Overview

This VS Code extension provides comprehensive language support for Microsoft Dynamics NAV C/AL (NAV 2013-2018), a legacy business programming language. The extension targets C/AL text exports (`.cal` and `.txt` files).

**Version:** 0.4.6
**Min VS Code:** 1.80.0
**Test Suite:** 398 tests (~7s execution)

## Critical Language Distinction ⚠️

**C/AL ≠ AL**
- C/AL: NAV 2009-2018 (this extension)
- AL: Business Central 2019+ (NOT supported)
- **Never add AL-only features** - they cause compilation errors in NAV

See `.claude/skills/cal-al-boundaries/SKILL.md` for complete boundaries.

## Architecture

```
Root/
├── syntaxes/              # TextMate grammar (syntax highlighting)
├── src/extension.ts       # Extension entry point (LSP client)
├── server/                # Language Server (TypeScript)
│   ├── src/
│   │   ├── lexer/         # Tokenization with context awareness
│   │   ├── parser/        # AST generation
│   │   ├── types/         # Type definitions (AST nodes, tokens)
│   │   ├── utils/         # Symbol table, visitor pattern
│   │   ├── providers/     # Base provider class
│   │   ├── completion/    # IntelliSense
│   │   ├── hover/         # Hover information
│   │   ├── definition/    # Go-to-definition
│   │   ├── references/    # Find all references
│   │   ├── signatureHelp/ # Parameter hints
│   │   └── semanticTokens/# Semantic highlighting (v0.3.0+)
│   └── performance/       # Performance benchmarks (v0.4.9+)
└── .claude/
    ├── skills/            # Domain knowledge (8 skills)
    └── agents/            # Specialized assistants (7 agents)
```

## Common Commands

### Build & Development
```bash
npm run compile          # Build extension + server
npm run watch           # Watch mode for development
npm run lint            # ESLint validation
```

### Testing
```bash
cd server && npm test                 # Run all 398 tests (~7s)
cd server && npm test -- --watch      # Watch mode
cd server && npm test -- --coverage   # With coverage report
cd server && npm test -- -u           # Update snapshots
```

**Important:** Delegate test execution to `test-runner` agent to save main context.

### Performance Testing
```bash
cd server && npm run perf:quick      # Quick benchmark
cd server && npm run perf:standard   # Standard suite
cd server && npm run perf:stress     # Stress testing
cd server && npm run perf:memory     # Memory profiling
```

### Debugging
- Press F5 in VS Code to launch Extension Development Host
- Open a `.cal` file to test language features
- Use Debug Console for language server logs

## Coding Standards

### TypeScript Style
- **No `any` types** - use proper typing or `unknown`
- **Null safety** - handle undefined cases explicitly
- **Error handling** - wrap risky operations in try-catch
- **Function length** - keep under 50 lines (extract helpers)
- **LSP best practices** - follow Language Server Protocol patterns

### Testing Standards
- **Test location:** `server/src/<feature>/__tests__/*.test.ts`
- **Naming:** Descriptive - `it('should parse TEMPORARY keyword in table variables')`
- **Coverage:** >80% for new code
- **Snapshot tests:** Use real C/AL from `cal-open-library`
- **Performance baseline:** ~7s for full suite

### C/AL-Specific Patterns

#### Context-Dependent Curly Braces
**Most critical C/AL concept:**
- In `FIELDS`/`KEYS`/`CONTROLS`: `{ }` are **structural delimiters**
- In `CODE` blocks (inside `BEGIN`/`END`): `{ }` are **comments**
- Pattern `{ Number ;` always indicates structure, never comment

#### @ Numbering System
- All variables/procedures have unique `@` numbers
- Example: `Customer@1001 : Record 18;`
- Auto-generated by C/SIDE, must be preserved in parsing

#### Keywords
- Convention: UPPERCASE (`BEGIN`, `END`, `IF`)
- Language is case-insensitive but UPPERCASE is standard

## Key Architectural Patterns

### Visitor Pattern (v0.4.x+)
- Base visitor: `utils/visitor.ts`
- Used by providers for AST traversal
- Clean separation of traversal from business logic

### Provider Base Class
- Abstract base: `providers/baseProvider.ts`
- All LSP providers extend this
- Shared symbol resolution, error handling, document management

### Semantic Tokens (v0.3.0+)
- AST-based intelligent highlighting
- Token types: namespace, class, function, variable, parameter, property
- Modifiers: declaration, readonly, static, deprecated

## Development Workflows

### Adding a New Keyword
1. Add token type to `server/src/lexer/lexer.ts`
2. Update parser grammar in `server/src/parser/parser.ts`
3. Add AST node type to `server/src/types/ast.ts` (if needed)
4. Update visitor pattern if applicable
5. Write tests in `server/src/lexer/__tests__/`
6. Verify with snapshot tests

### Fixing Parser Issues
1. Write failing test first (regression test)
2. Debug with `npm test -- --watch`
3. Fix in lexer or parser
4. Verify AST structure is correct
5. Update snapshots if needed

### Adding LSP Feature
1. Create provider extending `BaseProvider`
2. Implement required LSP interface methods
3. Register in `server/src/server.ts`
4. Write tests in `<feature>/__tests__/`
5. Test in Extension Development Host

## Available Skills (Domain Knowledge)

Use `/` commands to access specialized knowledge:

- `cal-basics` - Project structure, C/AL vs AL distinction
- `cal-syntax` - Keywords, operators, data types, @ numbering
- `cal-al-boundaries` - What NOT to add (AL-only features)
- `cal-extension-dev` - Architecture, testing, development guidelines
- `cal-object-format` - C/AL text export format, curly brace context
- `cal-testing-guide` - Jest testing, snapshots, performance tests
- `cal-parser-development` - Lexer, parser, visitor pattern, AST
- `cal-provider-development` - LSP providers, symbol table, semantic tokens

## Available Agents (Specialized Assistants)

Delegate specialized work to agents (saves main context):

- `architect` - Architectural reviews (Opus)
- `cal-expert` - C/AL language correctness (Sonnet)
- `typescript-reviewer` - Code quality checks (Sonnet)
- `test-runner` ⭐ - **Run tests in isolated context** (Haiku - saves ~30K tokens!)
- `performance-specialist` - Performance optimization (Opus)
- `test-writer` - Write comprehensive tests (Sonnet)
- `refactoring-guide` - Strategic refactoring (Opus)

**Pro tip:** Always use `test-runner` agent for test execution to keep main conversation clean.

## Known Limitations

- **Curly brace ambiguity** - TextMate grammar uses heuristics (can fail on edge cases)
- **Cross-file navigation** - Limited (needs workspace-wide indexing)
- **Syntax validation** - No compiler integration
- **Auto-formatting** - Complex due to fixed-width sections

## Performance Considerations

- **Lexer baseline:** Fast tokenization for typical files
- **Parser baseline:** ~7s for 398 tests
- **Memory:** Monitor with v8-profiler in performance tests
- **Large files:** Test with >1000 line procedures

## Test Data Sources

- **Microsoft cal-open-library** - Real NAV standard code
- **NAV demo databases** - Exports from official demos
- **Regression fixtures** - `server/src/__tests__/fixtures/`

## Documentation References

- **NAV 2018 Docs:** https://learn.microsoft.com/en-us/previous-versions/dynamicsnav-2018-developer/
- **cal-open-library:** https://github.com/microsoft/cal-open-library
- **LSP Specification:** https://microsoft.github.io/language-server-protocol/

## Version-Specific Features

| Feature | NAV 2013 | NAV 2016 | NAV 2018 | BC 15+ |
|---------|----------|----------|----------|--------|
| Basic C/AL | ✅ | ✅ | ✅ | ❌ |
| FOREACH loop | ❌ | ✅ | ✅ | ✅ |
| .NET events | ❌ | ✅ | ✅ | ✅ |
| ENUM type | ❌ | ❌ | ❌ | AL only |
| Extensions | ❌ | ❌ | ❌ | AL only |

Minimum supported: **NAV 2013**
Maximum supported: **BC 13/14** (last with C/AL)

## Security & Quality

- Run ESLint before commits
- No hardcoded credentials
- Validate user input in providers
- Handle errors gracefully (don't crash LSP server)
- Test error recovery paths

## GitHub Workflow

### Repository
- **Issue Tracking:** GitHub Issues used for bug reports, feature requests, and task management
- **Labels:** Use appropriate labels (bug, enhancement, documentation, etc.)

### Working with Issues
```bash
# List open issues
gh issue list

# View specific issue
gh issue view <number>

# Create new issue
gh issue create --title "Issue title" --body "Description"

# Comment on issue
gh issue comment <number> --body "Comment text"

# Close issue
gh issue close <number>
```

### Commit Messages
- Reference issues: `fix: resolve parser error with TEMPORARY keyword (#123)`
- Use conventional commits: `feat:`, `fix:`, `docs:`, `test:`, `refactor:`, `perf:`
- Include context for future maintainers

### Pull Request Workflow
1. Create feature branch: `git checkout -b feature/description`
2. Make changes and commit
3. Push to GitHub: `git push -u origin feature/description`
4. Create PR: `gh pr create --title "Title" --body "Description"`
5. Link to related issues: `Closes #123`
6. Wait for CI/CD checks (tests must pass)
7. Address review comments
8. Merge when approved

### CI/CD Expectations
- All tests must pass
- ESLint validation must succeed
- No TypeScript compilation errors
- Performance benchmarks should not regress >20%
